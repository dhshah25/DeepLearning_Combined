{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_squared_log_error\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchinfo import summary\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/Users/hp/Downloads/archive/realAWSCloudwatch/realAWSCloudwatch/ec2_cpu_utilization_5f5533.csv\"\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "target_feature = df.columns[1]\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(df['timestamp'], df[target_feature], color='b')\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(target_feature)\n",
    "plt.title(f\"Time-Series Plot of {target_feature}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df.select_dtypes(include=[np.number])\n",
    "df_numeric.boxplot()\n",
    "plt.title(\"Boxplot of Numeric Features\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "sns.histplot(df[target_feature], bins=30, kde=True)\n",
    "plt.xlabel(target_feature)\n",
    "plt.title(f\"Distribution of {target_feature}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset Head:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataset Shape:\", df.shape)\n",
    "print(\"Number of samples (time points):\", df.shape[0])\n",
    "print(\"Number of features:\", df.select_dtypes(include=[np.number]).shape[1])\n",
    "\n",
    "print(\"\\nMissing values in each column:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(df.describe().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset represents the CPU utilization of Amazon EC2 instances which is collected via AWS CloudWatch. It provides time-series measurements with key variables such as a timestamp and CPU utilization percentage, which can be used to monitor and analyze the performance of cloud resources.\n",
    "link to dataset: https://www.kaggle.com/datasets/boltzmannbrain/nab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df.select_dtypes(include=[np.number])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tensor = torch.tensor(df_scaled, dtype=torch.float32)\n",
    "\n",
    "train_data, test_data = train_test_split(data_tensor, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(TensorDataset(train_data), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(val_data), batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(TensorDataset(test_data), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_test_loss(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            batch_data = batch[0]\n",
    "            output = model(batch_data)\n",
    "            loss = criterion(output, batch_data)\n",
    "            total_loss += loss.item() * batch_data.size(0)\n",
    "            count += batch_data.size(0)\n",
    "    return total_loss / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_sizes, dropout_rate):\n",
    "        super(DenseAutoencoder, self).__init__()\n",
    "        encoder_layers = []\n",
    "        prev_dim = input_dim\n",
    "        for h in hidden_sizes:\n",
    "            encoder_layers.append(nn.Linear(prev_dim, h))\n",
    "            encoder_layers.append(nn.BatchNorm1d(h))\n",
    "            encoder_layers.append(nn.LeakyReLU(0.1))\n",
    "            encoder_layers.append(nn.Dropout(dropout_rate))\n",
    "            prev_dim = h\n",
    "        self.encoder = nn.Sequential(*encoder_layers)\n",
    "        \n",
    "        decoder_layers = []\n",
    "        rev_hidden = list(reversed(hidden_sizes))\n",
    "        for i, h in enumerate(rev_hidden[1:]):\n",
    "            decoder_layers.append(nn.Linear(prev_dim, h))\n",
    "            decoder_layers.append(nn.BatchNorm1d(h))\n",
    "            decoder_layers.append(nn.LeakyReLU(0.1))\n",
    "            prev_dim = h\n",
    "        decoder_layers.append(nn.Linear(prev_dim, input_dim))\n",
    "        self.decoder = nn.Sequential(*decoder_layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1DAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, channels, kernel_size=3):\n",
    "        super(Conv1DAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=channels[0], kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(channels[0], channels[1], kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(channels[1], channels[0], kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(channels[0], 1, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Conv1d) or isinstance(m, nn.ConvTranspose1d):\n",
    "            nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, num_layers=2, seq_length=10):\n",
    "        super(LSTMAutoencoder, self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "        self.encoder = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.decoder = nn.LSTM(hidden_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_dim, input_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        _, (hidden, cell) = self.encoder(x)\n",
    "        decoder_input = torch.zeros((x.shape[0], self.seq_length, hidden.shape[2]), device=x.device)\n",
    "        decoded, _ = self.decoder(decoder_input, (hidden, cell))\n",
    "        decoded = self.output_layer(decoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        sequences.append(data[i:i + seq_length])\n",
    "    return torch.stack(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_conv1d = torch.tensor(scaler.fit_transform(train_data.numpy()), dtype=torch.float32).unsqueeze(1)\n",
    "val_data_conv1d = torch.tensor(scaler.transform(val_data.numpy()), dtype=torch.float32).unsqueeze(1)\n",
    "test_data_conv1d = torch.tensor(scaler.transform(test_data.numpy()), dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "train_loader_conv1d = DataLoader(TensorDataset(train_data_conv1d), batch_size=batch_size, shuffle=True)\n",
    "val_loader_conv1d = DataLoader(TensorDataset(val_data_conv1d), batch_size=batch_size, shuffle=False)\n",
    "test_loader_conv1d = DataLoader(TensorDataset(test_data_conv1d), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 10\n",
    "train_data_lstm = create_sequences(train_data, seq_length)\n",
    "val_data_lstm = create_sequences(val_data, seq_length)\n",
    "test_data_lstm = create_sequences(test_data, seq_length)\n",
    "\n",
    "train_loader_lstm = DataLoader(TensorDataset(train_data_lstm), batch_size=batch_size, shuffle=True)\n",
    "val_loader_lstm = DataLoader(TensorDataset(val_data_lstm), batch_size=batch_size, shuffle=False)\n",
    "test_loader_lstm = DataLoader(TensorDataset(test_data_lstm), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=50, model_name=\"model\"):\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    train_losses, val_losses = [], []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch in train_loader:\n",
    "            batch_data = batch[0]\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch_data)\n",
    "            loss = criterion(output, batch_data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch_data = batch[0]\n",
    "                output = model(batch_data)\n",
    "                loss = criterion(output, batch_data)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        print(f\"[{model_name}] Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}\")\n",
    "        \n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            # Save best model weights for this architecture to a dedicated file\n",
    "            torch.save(best_model_wts, f\"/Users/hp/Desktop/best_{model_name}_weights.pt\")\n",
    "        \n",
    "        # Early stopping if validation loss increases after 10 epochs\n",
    "        if epoch > 10 and avg_val_loss > val_losses[-2]:\n",
    "            print(f\"[{model_name}] Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_scheduler(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=50, model_name=\"model\"):\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    train_losses, val_losses = [], []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch in train_loader:\n",
    "            batch_data = batch[0]\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch_data)\n",
    "            loss = criterion(output, batch_data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch_data = batch[0]\n",
    "                output = model(batch_data)\n",
    "                loss = criterion(output, batch_data)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        scheduler.step(avg_val_loss)\n",
    "        print(f\"[{model_name}] Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}\")\n",
    "        \n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            torch.save(best_model_wts, f\"/Users/hp/Desktop/best_{model_name}_weights.pt\")\n",
    "            \n",
    "        if epoch > 10 and avg_val_loss > val_losses[-2]:\n",
    "            print(f\"[{model_name}] Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_reconstruction_error(model, test_loader):\n",
    "    model.eval()\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            batch_data = batch[0]\n",
    "            output = model(batch_data)\n",
    "            # Compute MSE per sample\n",
    "            loss = torch.mean((output - batch_data) ** 2, dim=1)\n",
    "            errors.extend(loss.cpu().numpy())\n",
    "    return np.array(errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(train_losses, val_losses, title):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss (MSE)\")\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reconstruction_error_distribution(errors, title):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.histplot(errors, bins=50, kde=True)\n",
    "    plt.xlabel(\"Reconstruction Error (MSE)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_anomaly_detection(errors, threshold, title):\n",
    "    anomalies = errors > threshold\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(errors, label=\"Reconstruction Error\")\n",
    "    plt.axhline(y=threshold, color='r', linestyle='--', label=\"Threshold (95th percentile)\")\n",
    "    plt.scatter(np.where(anomalies)[0], errors[anomalies], color='red', label=\"Anomalies\")\n",
    "    plt.xlabel(\"Test Data Points\")\n",
    "    plt.ylabel(\"Reconstruction Error (MSE)\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_configs = [\n",
    "    {\"name\": \"dense_config1\", \"hidden_sizes\": [64, 32, 16], \"dropout_rate\": 0.2},\n",
    "    {\"name\": \"dense_config2\", \"hidden_sizes\": [128, 64, 32], \"dropout_rate\": 0.3}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dense_val_loss = float('inf')\n",
    "best_dense_model = None\n",
    "dense_experiment_results = {}\n",
    "\n",
    "for config in dense_configs:\n",
    "    print(f\"\\nTraining Dense Autoencoder with config: {config}\")\n",
    "    model_dense = DenseAutoencoder(input_dim=df_scaled.shape[1],\n",
    "                                   hidden_sizes=config[\"hidden_sizes\"],\n",
    "                                   dropout_rate=config[\"dropout_rate\"])\n",
    "    print(\"Dense Model Summary:\")\n",
    "    print(summary(model_dense, (1, df_scaled.shape[1])))\n",
    "    optimizer_dense = optim.Adam(model_dense.parameters(), lr=0.001)\n",
    "    train_losses_dense, val_losses_dense = train_model(model_dense, train_loader, val_loader, nn.MSELoss(), optimizer_dense, epochs=50, model_name=config[\"name\"])\n",
    "    min_val_loss = min(val_losses_dense)\n",
    "    dense_experiment_results[config[\"name\"]] = min_val_loss\n",
    "    \n",
    "    if min_val_loss < best_dense_val_loss:\n",
    "        best_dense_val_loss = min_val_loss\n",
    "        best_dense_model = copy.deepcopy(model_dense)\n",
    "        torch.save(best_dense_model.state_dict(), \"/Users/hp/Desktop/best_dense_autoencoder_weights.pt\")\n",
    "\n",
    "print(\"\\nDense Autoencoder Experiment Results (Validation Loss):\")\n",
    "for cfg, loss in dense_experiment_results.items():\n",
    "    print(f\"Config {cfg}: Best Val Loss = {loss:.6f}\")\n",
    "print(\"Best Dense Autoencoder saved as 'best_dense_autoencoder_weights.pt'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_configs = [\n",
    "    {\"name\": \"conv_config1\", \"channels\": [16, 8], \"kernel_size\": 3},\n",
    "    {\"name\": \"conv_config2\", \"channels\": [32, 16], \"kernel_size\": 3}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_conv_val_loss = float('inf')\n",
    "best_conv_model = None\n",
    "conv_experiment_results = {}\n",
    "\n",
    "for config in conv_configs:\n",
    "    print(f\"\\nTraining Conv1D Autoencoder with config: {config}\")\n",
    "    model_conv = Conv1DAutoencoder(input_dim=df_scaled.shape[1],\n",
    "                                   channels=config[\"channels\"],\n",
    "                                   kernel_size=config[\"kernel_size\"])\n",
    "    initialize_weights(model_conv)\n",
    "    optimizer_conv = optim.Adam(model_conv.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer_conv, mode='min', patience=5, factor=0.5, verbose=True)\n",
    "    train_losses_conv, val_losses_conv = train_model_with_scheduler(model_conv, train_loader_conv1d, val_loader_conv1d, nn.MSELoss(), optimizer_conv, scheduler, epochs=50, model_name=config[\"name\"])\n",
    "    min_val_loss = min(val_losses_conv)\n",
    "    conv_experiment_results[config[\"name\"]] = min_val_loss\n",
    "    \n",
    "    if min_val_loss < best_conv_val_loss:\n",
    "        best_conv_val_loss = min_val_loss\n",
    "        best_conv_model = copy.deepcopy(model_conv)\n",
    "        torch.save(best_conv_model.state_dict(), \"/Users/hp/Desktop/best_conv1d_autoencoder_weights.pt\")\n",
    "\n",
    "print(\"\\nConv1D Autoencoder Experiment Results (Validation Loss):\")\n",
    "for cfg, loss in conv_experiment_results.items():\n",
    "    print(f\"Config {cfg}: Best Val Loss = {loss:.6f}\")\n",
    "print(\"Best Conv1D Autoencoder saved as 'best_conv1d_autoencoder_weights.pt'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_configs = [\n",
    "    {\"hidden_dim\": 32, \"num_layers\": 1},\n",
    "    {\"hidden_dim\": 64, \"num_layers\": 2},\n",
    "    {\"hidden_dim\": 128, \"num_layers\": 2}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lstm_val_loss = float('inf')\n",
    "best_lstm_config = None\n",
    "best_lstm_model = None\n",
    "lstm_experiment_results = {}\n",
    "\n",
    "for config in lstm_configs:\n",
    "    config_name = f\"lstm_hd{config['hidden_dim']}_nl{config['num_layers']}\"\n",
    "    print(f\"\\nTraining LSTM Autoencoder with config: hidden_dim={config['hidden_dim']}, num_layers={config['num_layers']}\")\n",
    "    model_lstm = LSTMAutoencoder(input_dim=df_scaled.shape[1], hidden_dim=config['hidden_dim'], num_layers=config['num_layers'], seq_length=seq_length)\n",
    "    print(\"LSTM Model Summary:\")\n",
    "    print(summary(model_lstm, (1, seq_length, df_scaled.shape[1])))\n",
    "    optimizer_lstm = optim.Adam(model_lstm.parameters(), lr=0.001)\n",
    "    train_losses_lstm, val_losses_lstm = train_model(model_lstm, train_loader_lstm, val_loader_lstm, nn.MSELoss(), optimizer_lstm, epochs=50, model_name=config_name)\n",
    "    min_val_loss = min(val_losses_lstm)\n",
    "    lstm_experiment_results[config_name] = min_val_loss\n",
    "    \n",
    "    if min_val_loss < best_lstm_val_loss:\n",
    "        best_lstm_val_loss = min_val_loss\n",
    "        best_lstm_config = config\n",
    "        best_lstm_model = copy.deepcopy(model_lstm)\n",
    "\n",
    "print(\"\\nLSTM Autoencoder Experiment Results (Validation Loss):\")\n",
    "for cfg, loss in lstm_experiment_results.items():\n",
    "    print(f\"Config {cfg}: Best Val Loss = {loss:.6f}\")\n",
    "print(\"Best LSTM Configuration:\", best_lstm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_lstm_model.state_dict(), \"/Users/hp/Desktop/best_lstm_autoencoder_weights.pt\")\n",
    "print(\"Best LSTM Autoencoder weights saved as 'best_lstm_autoencoder_weights.pt'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "test_loss_dense = compute_test_loss(best_dense_model, test_loader, criterion)\n",
    "reconstruction_errors_dense = compute_reconstruction_error(best_dense_model, test_loader)\n",
    "threshold_dense = np.percentile(reconstruction_errors_dense, 95)\n",
    "\n",
    "\n",
    "print(\"\\n[Dense] Test Loss (MSE):\", test_loss_dense)\n",
    "print(\"[Dense] Anomaly Detection Threshold (95th percentile):\", threshold_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies_dense = reconstruction_errors_dense > threshold_dense\n",
    "print(\"[Dense] Number of anomalies detected:\", np.sum(anomalies_dense))\n",
    "\n",
    "predictions_dense = best_dense_model(test_data).detach().numpy()\n",
    "test_data_np = test_data.numpy()\n",
    "shift_value = abs(min(test_data_np.min(), predictions_dense.min())) + 1\n",
    "mae_dense = mean_absolute_error(test_data_np, predictions_dense)\n",
    "rmse_dense = np.sqrt(mean_squared_error(test_data_np, predictions_dense))\n",
    "r2_dense = r2_score(test_data_np, predictions_dense)\n",
    "msle_dense = mean_squared_log_error(test_data_np + shift_value, predictions_dense + shift_value)\n",
    "print(f\"[Dense] MAE: {mae_dense:.6f}, RMSE: {rmse_dense:.6f}, R²: {r2_dense:.6f}, MSLE: {msle_dense:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_conv = compute_test_loss(best_conv_model, test_loader_conv1d, criterion)\n",
    "reconstruction_errors_conv = compute_reconstruction_error(best_conv_model, test_loader_conv1d)\n",
    "threshold_conv = np.percentile(reconstruction_errors_conv, 95)\n",
    "\n",
    "print(\"\\n[Conv1D] Test Loss (MSE):\", test_loss_conv)\n",
    "print(\"[Conv1D] Anomaly Detection Threshold (95th percentile):\", threshold_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies_conv = reconstruction_errors_conv > threshold_conv\n",
    "print(\"[Conv1D] Number of anomalies detected:\", np.sum(anomalies_conv))\n",
    "\n",
    "test_data_np_conv = test_data_conv1d.squeeze(1).numpy()\n",
    "predictions_conv = best_conv_model(test_data_conv1d.clone().detach()).detach().squeeze(1).numpy()\n",
    "shift_value = abs(min(test_data_np_conv.min(), predictions_conv.min())) + 1\n",
    "mae_conv = mean_absolute_error(test_data_np_conv, predictions_conv)\n",
    "rmse_conv = np.sqrt(mean_squared_error(test_data_np_conv, predictions_conv))\n",
    "r2_conv = r2_score(test_data_np_conv, predictions_conv)\n",
    "msle_conv = mean_squared_log_error(test_data_np_conv + shift_value, predictions_conv + shift_value)\n",
    "print(f\"[Conv1D] MAE: {mae_conv:.6f}, RMSE: {rmse_conv:.6f}, R²: {r2_conv:.6f}, MSLE: {msle_conv:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_lstm = compute_test_loss(best_lstm_model, test_loader_lstm, criterion)\n",
    "reconstruction_errors_lstm = compute_reconstruction_error(best_lstm_model, test_loader_lstm)\n",
    "threshold_lstm = np.percentile(reconstruction_errors_lstm, 95)\n",
    "\n",
    "print(\"\\n[LSTM] Test Loss (MSE):\", test_loss_lstm)\n",
    "print(\"[LSTM] Anomaly Detection Threshold (95th percentile):\", threshold_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies_lstm = reconstruction_errors_lstm > threshold_lstm\n",
    "print(\"[LSTM] Number of anomalies detected:\", np.sum(anomalies_lstm))\n",
    "\n",
    "test_data_np_lstm = test_data_lstm.numpy().squeeze(-1)\n",
    "predictions_lstm = best_lstm_model(test_data_lstm.clone().detach()).detach().numpy().squeeze(-1)\n",
    "shift_value = abs(min(test_data_np_lstm.min(), predictions_lstm.min())) + 1\n",
    "mae_lstm = mean_absolute_error(test_data_np_lstm, predictions_lstm)\n",
    "rmse_lstm = np.sqrt(mean_squared_error(test_data_np_lstm, predictions_lstm))\n",
    "r2_lstm = r2_score(test_data_np_lstm, predictions_lstm)\n",
    "msle_lstm = mean_squared_log_error(test_data_np_lstm + shift_value, predictions_lstm + shift_value)\n",
    "print(f\"[LSTM] MAE: {mae_lstm:.6f}, RMSE: {rmse_lstm:.6f}, R²: {r2_lstm:.6f}, MSLE: {msle_lstm:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_lstm_model.state_dict(), \"/Users/hp/Desktop/best_selected_lstm_autoencoder_weights.pt\")\n",
    "print(\"Best selected LSTM Autoencoder weights saved as 'best_selected_lstm_autoencoder_weights.pt'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(train_losses_dense, val_losses_dense, \"Dense Autoencoder - Training & Validation Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reconstruction_error_distribution(reconstruction_errors_dense, \"Dense Autoencoder - Reconstruction Error Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_anomaly_detection(reconstruction_errors_dense, threshold_dense, \"Dense Autoencoder - Anomaly Detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(train_losses_conv, val_losses_conv, \"Conv1D Autoencoder - Training & Validation Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reconstruction_error_distribution(reconstruction_errors_conv, \"Conv1D Autoencoder - Reconstruction Error Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_anomaly_detection(reconstruction_errors_conv, threshold_conv, \"Conv1D Autoencoder - Anomaly Detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(train_losses_lstm, val_losses_lstm, \"LSTM Autoencoder - Training & Validation Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reconstruction_error_distribution(reconstruction_errors_lstm, \"LSTM Autoencoder - Reconstruction Error Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_anomaly_detection(reconstruction_errors_lstm, threshold_lstm, \"LSTM Autoencoder - Anomaly Detection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I have chosen 95 percentile as a thresold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Architecture**\n",
    "\n",
    "- The final autoencoder that we have decided is the LSTM. It uses the best configuration discovered during experimentation, which is 2 LSTM layers with a hidden dimension of 128. In this model, the encoder processes input sequences of 10 time steps and compresses the temporal features into a 128-dimensional hidden representation, this captures both short-term and long-term dependencies in the CPU utilization data.\n",
    "- Here, the decoder mirrors the encoder by using 2 LSTM layers to reconstruct the original sequence from the learned representation. Then, there is a fully connected layer that maps the decoder output back to the original feature space. We haven't included dropout in this specific configuration but it can be added if regularization becomes necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result and Analyis**\n",
    "\n",
    "- We have evaluated the performance of the LSTM autoencoder using reconstruction metrics such as Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), R2, and Mean Squared Log Error (MSLE).\n",
    "- Here, the training and validation loss curves shows smooth convergence, which indicates that the model was able to effectively learn the temporal dynamics. We have set the anomaly threshold at the 95th percentile of the reconstruction error distribution, this enables the detection of unusual patterns in CPU utilization.\n",
    "- One issue was the model occasionally under-predicted sudden spikes in CPU usage. So, it is important to tune hyperparameters like increasing the hidden dimension to 128 and using 2 layers can improve the model’s capacity to capture complex temporal patterns.\n",
    "- R2 is very high and I think that's fine because we have already defined a thresold of 95 and it allows some level of reconstruction error and even after that some of the points are not reconstructed close to actual value. But the good thing is the reconstruction error is very less."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Strength and Limitations**\n",
    "\n",
    "- Autoencoders like LSTM-based models are good in unsupervised anomaly detection by learning a compressed representation of normal behavior without requiring labeled anomalies. This makes them highly effective when anomalies are rare or vary widely in appearance. They are able to reconstruct input data, which allows to flag instances with high reconstruction error as potential anomalies. \n",
    "- However, choosing an appropriate threshold for anomaly detection is challenging and can lead to false positives or negatives. Additionally, the performance of autoencoders is sensitive to hyperparameter choices. Here, increasing capacity like using a hidden dimension of 128 and multiple layers enhances pattern recognition but it also requires careful tuning to avoid overfitting as well as to ensure that subtle anomalies like short-lived spikes may not cause issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References:** <br>\n",
    "\n",
    "https://matplotlib.org/stable/plot_types/index.html <br>\n",
    "https://numpy.org/doc/stable/user/index.html#user <br>\n",
    "https://seaborn.pydata.org/tutorial/introduction.html <br>\n",
    "https://pytorch.org/docs/stable/index.html <br>\n",
    "https://scikit-learn.org/stable/ <br>\n",
    "https://pandas.pydata.org/docs/user_guide/index.html#user-guide <br>\n",
    "https://arxiv.org/pdf/2003.05991"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
