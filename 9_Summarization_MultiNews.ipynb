{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hxFv_wh-G7cE",
    "outputId": "263c1cda-c5d0-4113-d405-65075a45141e"
   },
   "outputs": [],
   "source": [
    "!pip install datasets transformers evaluate sacrebleu bert_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BdQqnLAbG9c7",
    "outputId": "9ef21b9b-77c7-4de7-c2a5-4f712ae5f97a"
   },
   "outputs": [],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mt0VrUTIhk98"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import (\n",
    "    BartForConditionalGeneration,\n",
    "    BartTokenizer,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "import evaluate\n",
    "import sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wxolALyAhm3i"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NJLKiYaXhpYN",
    "outputId": "36c23006-2a87-4702-ce37-f3d70079651c"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"alexfabbri/multi_news\", trust_remote_code=True)\n",
    "print(\"Original splits:\", dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BuNy2PfNhqFi",
    "outputId": "044b2f3d-652e-4aea-8588-f13448cfe56e"
   },
   "outputs": [],
   "source": [
    "for split in dataset.keys():\n",
    "    print(f\"Split: {split}, Number of samples: {len(dataset[split])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ldUkRaBjht-N"
   },
   "outputs": [],
   "source": [
    "if \"validation\" not in dataset.keys():\n",
    "    train_valid = dataset[\"train\"].train_test_split(test_size=0.1, seed=seed)\n",
    "    dataset = DatasetDict({\n",
    "        \"train\": train_valid[\"train\"],\n",
    "        \"validation\": train_valid[\"test\"],\n",
    "        \"test\": dataset[\"test\"]\n",
    "    })\n",
    "    print(\"After splitting, splits:\", dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "b357c5274e7346e884b95196ab044ce9",
      "ebd81bf8080840109149f452b4c8f707",
      "e92134f44ec142df96e79ef669138982",
      "feccc17efb6045abaae36583c8153665",
      "42d76510b6534899bcec107cb9b0532d",
      "43f0a6949af74f5d94386028f9082396",
      "2108cb28f90d4cd7a67fe7b7fdb15aee",
      "8f22bb01296f4f07b30c87b587a7da25",
      "efbfa5bcf9ce4866843404af377263cf",
      "561d311612bc4d81b9ce591133bfa80d",
      "27ec305b74204558b789c5a074893300",
      "c400722ac1974811a7cacc405716a33b",
      "60c903772fa1456381553907459c3bb3",
      "33ac696788c14b95bbae962b11832699",
      "faa9bb29217f4245a3f61abad3bc41da",
      "f18e0a5b6a624e998cfb0a0554f2e45c",
      "61e60d2bb764441a8fdcd48849cfb740",
      "b437a74392614e2e8d41b8fc6560f924",
      "94900f11f2794f1b939f90bae37fded0",
      "192709b313f94ea8b29b43768d5ada0c",
      "0163588debe2490593863942215b6097",
      "1fe5e7d4d52049bfb9502aea20359291",
      "1247274968d14d048a1d8eb83561294d",
      "92df419d97144882b7bed5f70850b797",
      "56bed8c01820469dad4e9e75af034843",
      "c18f3f0004db4959bb8a21bf5ca883a6",
      "9c87b12ff0a74b54a88f2051c72e6632",
      "1db68a2a2e4140fd9c5eb11b4c9255e7",
      "7189473e74e2440281cdb3de1a7ad4d6",
      "f87993e5a56b4916972e3835a3e08e3a",
      "7b2bc6aa8b0240b493bb613addd876ad",
      "c91f6d3d5bbf423f87e6099594b50da3",
      "951d40614cdc47799b4e1672efb83dfd",
      "1ec3ee32fcf34a21a00d8a80231cace4",
      "eefc30af396c404cb01c9f9ac21b241c",
      "3c2c53c4af4e4726837fca6b1244b49a",
      "cbf147057f444c49a94e59747d8b6d7b",
      "a30aaba2c4db4163b80da127a4ecfaed",
      "bdb27bbcf81e4193b4524499835a4caf",
      "fa3428f80842429aa4dc119db9e9388a",
      "6492631cfa464f34a7b238e6af90618f",
      "341569a5d9274ad89a30a5cb32dd5088",
      "b96abd7a7cb94ed8af5732fc765a2791",
      "76024c89aedf4703bd745a74f61426a6"
     ]
    },
    "id": "QwK2ogBMhv9E",
    "outputId": "07af9095-bf00-4c6f-e71e-354900c90683"
   },
   "outputs": [],
   "source": [
    "model_checkpoint = \"facebook/bart-base\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rnRCb57EhzZ3"
   },
   "outputs": [],
   "source": [
    "max_input_length = 1024\n",
    "max_target_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167,
     "referenced_widgets": [
      "507496d8efe245de8834620e4be75863",
      "a37530ec3f8c467bba84c16bf76d080f",
      "c3a65b8b005244dcaa23874e5eb757f7",
      "f7feb82f97bc498e9fe25bf9d634cb83",
      "22f0fc36b8aa46a394e733c28a72d5e8",
      "84f3a475a7ba430f82584a3cd29b0ede",
      "5f85026d0e8c40b18bf32d155fe633c6",
      "4f0178ea78e4403a9ca0f7cb53660915",
      "0bb8901d621b44ecafa22524f8ceb227",
      "7da4e7eae63549c292e579151f973625",
      "0f7ad41fcb1a450c8905d5933125a168",
      "504499f3d0004e3b9826024ab7ede4e7",
      "59275be8bcfe4d21b481f429fce98bb3",
      "a7ba8f45e1144fd692544456294ed1c8",
      "9497c78a429d4c4988b6a6a6c5f34a3c",
      "78772a5bf64848618858a1acc86b90ce",
      "6918496e8e9f47c8a963930d78c5a7bf",
      "de6ae0b4318c481fbfac9053f875ff06",
      "10c9831d0e204a6f9269e780c4fa8e9b",
      "c918b7cf6d64459a80ade760953c2be8",
      "ec2cf3ff1d2f49b8b927585dec3a6959",
      "f956abc6155c4c49863afc018cb8b335",
      "690d560c393e475cb8ecbaeb193be469",
      "1fbde5a890074f158c3858058577d79a",
      "1fbc41185b7649f49c863394ef8cc354",
      "2a4a0f77f7c84008940912c37aa47f1c",
      "5fa88ccd575542b6b367067ce1d5eecb",
      "823a1ccf5f184a148d19ba9968daf63e",
      "1cecde3f664b4498a3999d2b0c093856",
      "125020805c7e4a3f91345a78da03beb1",
      "8ff517bc1874472ba238411cc47979fa",
      "5a273f1e6a8440ed94a82c8e8b3b2fda",
      "2254ca85551e47dbb4002df1fec0dc6d"
     ]
    },
    "id": "OmyzsRewiA8y",
    "outputId": "a597bdc8-b0ab-4b02-c1c7-775ee14fa653"
   },
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    model_inputs = tokenizer(examples[\"document\"], max_length=max_input_length, truncation=True)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"summary\"], max_length=max_target_length, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=[\"document\", \"summary\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130,
     "referenced_widgets": [
      "908e56c860a64ae681afbdf7bcdf4c1c",
      "7781cc4d91b04dcdad7926f8ad91aaa7",
      "72f6a7e4c94b49da99d54a037236e024",
      "d38b89ea641544da8f6c68fc93312ec0",
      "4cb8e1a042c64762b33825782f9a52e2",
      "d0411c50dd634fc591f862cb58f04202",
      "29be930868bc43c7a6ca0133f28e220b",
      "52b01caf3409404db1f0f64a6eb016b7",
      "66b199059f514438bb80a0dbc08525c3",
      "4fc6b21ec62940368644fd28daaea397",
      "82387d268d3a4de485b7c04d97bfebb7",
      "4a39dc7a39834f16aa7203225baa7dd4",
      "2c56dd992dc74f7b8c9b805f958de901",
      "613e1376d967419da2279e086eb6ea2f",
      "a8ad51e7a9c34ea6b6c6c450563490e8",
      "269c559a227847168832f663b73cbcbd",
      "9a8ccdcc1a0d472991033fb27acc4449",
      "6aeef4aa142347cf87f585d3df916287",
      "7c0948e29c294a429371b4e76657ac79",
      "bab82e613fc34928ace8b13212b1cb9f",
      "190313adb46b4ea2984c73b857be2759",
      "461ae46ad8464d0aab03172cc330e0f0",
      "7b5b2b8ef9564494be930e74060c1b9a",
      "3c1d827d8e514999865a19e2b67df388",
      "3182b7a2c5bb4b25ba4068b3869aa001",
      "b3bbb7e04f9b48c1a102662a148ed439",
      "a3525163d73d48c28b55464cd1ad5535",
      "54868c6b7ddd4e6d88e7ee13da191250",
      "9a4715cd56c049df9b7b738e45f50c70",
      "1f33ed5efd6540b785f97dd23d83e53f",
      "09da656a90544db1a839a6bba37f06dc",
      "45c0c527991340e7a397df279f42dec3",
      "52ef449242db490aa471dd63a719dff2"
     ]
    },
    "id": "Y3896K22iEWw",
    "outputId": "487b380c-6667-471c-b2de-c53c903d92ed"
   },
   "outputs": [],
   "source": [
    "tokenized_dataset_path = \"./tokenized_multinews\"\n",
    "if not os.path.exists(tokenized_dataset_path):\n",
    "    tokenized_datasets.save_to_disk(tokenized_dataset_path)\n",
    "    print(f\"Tokenized dataset saved to {tokenized_dataset_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jwPUXETniRuO"
   },
   "outputs": [],
   "source": [
    "min_train_samples = 1000\n",
    "min_valid_samples = 100\n",
    "if len(tokenized_datasets[\"train\"]) > min_train_samples:\n",
    "    tokenized_datasets[\"train\"] = tokenized_datasets[\"train\"].select(range(min_train_samples))\n",
    "if len(tokenized_datasets[\"validation\"]) > min_valid_samples:\n",
    "    tokenized_datasets[\"validation\"] = tokenized_datasets[\"validation\"].select(range(min_valid_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mz50YYK1iVCL"
   },
   "outputs": [],
   "source": [
    "class CustomSeq2SeqTrainer(Seq2SeqTrainer):\n",
    "    def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=None):\n",
    "        inputs = self._prepare_inputs(inputs)\n",
    "        generated_tokens = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_length=max_target_length,\n",
    "            num_beams=8,\n",
    "            length_penalty=1.5,\n",
    "            no_repeat_ngram_size=3,\n",
    "            min_length=50\n",
    "        )\n",
    "        labels = inputs.get(\"labels\")\n",
    "        loss = None\n",
    "        if not prediction_loss_only:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "                loss = outputs.loss\n",
    "        return (loss, generated_tokens, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "460fc8988f5742a297eb5f3044c8a13b",
      "3e226d85e68c40ee8e3d7f630752750a",
      "418fd2a4ca0b48a68681d09a0940b616",
      "0d248198603244adacd844e08b5bba86",
      "f06640fbb8ac4186a0fdc76bfe77825a",
      "9697e31f54fd4fca8f33ad920ef40685",
      "957e23a2834a47bc8f3bbf7d5a5cb46d",
      "f7ae6d0e4fa04c899b3f30073ed79b9e",
      "2d04ac34005247308bbf87baf6433c79",
      "9272f95bf1594a659086a454aa6fcc3d",
      "235d075b7a394b11b0a7be47d04b2ef1",
      "fcdce28fd71247e78819765abb1a38f8",
      "f81cfa1816444e98b111331470f0a919",
      "cd8fe42acfb549a1a9824aef217af3c9",
      "04e2f9413e0549bbb34e66098fe64abe",
      "0fba572b896049d29e1b709042e5c3f3",
      "dca6cebb44614e7d925570b64dcd91d2",
      "c69bf19bbcb44cf5ae2d0e0dff33c0d2",
      "dd33bdcf2a244e8fb9f9d8297fff5c4d",
      "e928412490cd407484c918ef12fe2d58",
      "882dfbfce05243e28adc490309e37960",
      "62c902b7edee43baadc0bcfcdd69d137",
      "22c9a10a99d54da8bc8450eb64a466df",
      "770667b910254e899292688f4ef8f716",
      "e1eb3a9dff6e447dbb1cf7b43deeea0b",
      "13a461c2b3984f649b6387f49f37e202",
      "b333b5a2ca04429481bc1e4e072c0f90",
      "a926ce91654940b3b687b5aca85449c0",
      "5adcae9ed45f4e179342866c3f703d37",
      "bc44ffdd07ac4c6fa510c22171a81d20",
      "f672cbe49cf043f18ad457458be58103",
      "634457acd9e54e998b963f0aafd7f8dd",
      "643942afa41b40218568b5c31135e387"
     ]
    },
    "id": "WZAZXCYYioFs",
    "outputId": "e0b8267f-ad16-449b-cf39-8a460b9b0dea"
   },
   "outputs": [],
   "source": [
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "sacrebleu_metric = evaluate.load(\"sacrebleu\")\n",
    "bertscore_metric = evaluate.load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qIdaGgT8iohl"
   },
   "outputs": [],
   "source": [
    "def safe_decode(batch_ids):\n",
    "    decoded_batch = []\n",
    "    for ids in batch_ids:\n",
    "        if isinstance(ids, np.ndarray):\n",
    "            ids = ids.tolist()\n",
    "        tokens = tokenizer.convert_ids_to_tokens(ids, skip_special_tokens=True)\n",
    "        tokens = [t if t is not None else \"\" for t in tokens]\n",
    "        decoded_batch.append(\"\".join(tokens))\n",
    "    return decoded_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-s5Q-qGiuXx"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = safe_decode(predictions)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = safe_decode(labels)\n",
    "\n",
    "    rouge_result = rouge_metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    bleu = sacrebleu.corpus_bleu(decoded_preds, [[ref] for ref in decoded_labels], smooth_method=\"exp\")\n",
    "    bleu_score = bleu.score\n",
    "    bertscore_result = bertscore_metric.compute(predictions=decoded_preds, references=decoded_labels, lang=\"en\")\n",
    "    avg_bertscore = np.mean(bertscore_result[\"f1\"])\n",
    "\n",
    "    return {\n",
    "        \"rouge1\": rouge_result[\"rouge1\"],\n",
    "        \"rouge2\": rouge_result[\"rouge2\"],\n",
    "        \"rougeL\": rouge_result[\"rougeL\"],\n",
    "        \"bleu\": bleu_score,\n",
    "        \"bertscore\": avg_bertscore\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IC4Fl1Qui2R0"
   },
   "outputs": [],
   "source": [
    "experiment_configs = [\n",
    "    {\"name\": \"config3\", \"learning_rate\": 5e-5, \"train_batch_size\": 4, \"num_train_epochs\": 3},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "4b259771e32a4efcb3ec4982c70e21f8",
      "72118f66faa5455b9887ffae0e892bd7",
      "5c9088e120f042548835875eb58cbc01",
      "8630b77fd2ac4657bb5b7154dfdbde1c",
      "76e5b1e3aef34f2690d4912acab4c1f6",
      "19e2ec0c00034137b7a3ecd4176832fa",
      "1a68e2b4cab14ab1a2edb9d02d0b5051",
      "c8e465b894e44f69b87d3de8d33a7ee7",
      "f01790d974ec4ebda4e877c0c8556ed7",
      "dac5770eafb147d1b1e799275baf6737",
      "315943001518423092f89b14a61c00c6"
     ]
    },
    "id": "p-6iamtKi5xc",
    "outputId": "8b5c748e-a99a-477f-a899-fc855348dc33"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=BartForConditionalGeneration.from_pretrained(model_checkpoint),\n",
    "    padding=\"longest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 757,
     "referenced_widgets": [
      "48322bd754b048a99abdd080c38d8d33",
      "b1a7d557fb7a4f7b93ae1c4e70a346ec",
      "61dcd21ae0e64ea58d5c46d800f6b7ea",
      "fe9e2a508e9a458eb2f67df0160ae723",
      "2e44e3807b46412b928326eab320d5c7",
      "1b0e6c48d3ca44c1ab140a97e52f3108",
      "7206cf21396348fb91ed1403329b2a42",
      "575ba2d9434d4482a43857e5668bcb63",
      "f54bdad307c9483b89c5f7b788697ee7",
      "a1a3e2387c9741d49254c07aa0f73129",
      "9d18f8c0ee8e4b278a66ebd7cdc0e844",
      "e395be88de9e4bc5888877ca16551a18",
      "f0cbb14364224b59a0f763cac4d51254",
      "eaaa672049904d768f1a505570c30ee5",
      "89ea0fb8368e45a9a60837affa079813",
      "722dd0a4c036417fa19f467ab0b68e50",
      "4494468167a6494294fd6b963959bade",
      "40d376cd21de4ca883cc479824181e5f",
      "af3a3188f4494892bdf65095da5218f8",
      "206c3648136d4cf7af22720bf1060db8",
      "1afefc53e42a4058aa637d646cf131e3",
      "ab20aa0e07844ccd85cda58e6f0bb1ad",
      "853db8e2d7ab4eaca938b8767155ff9d",
      "6ea8c1176e944150a183f7409d0c18f6",
      "ad7dc9a63ee84c52953c921b5baa8da2",
      "38e11bbc3dbc4200a1c656fe777f1752",
      "bf5f9ed4d8c04054a3186af5b993e1e8",
      "3971d00aa0e74ec1b258c24fd97dce86",
      "1a6dbc3fcd694866bb26ad3b4589b1eb",
      "0825b469a0fb4dd5b9e28b124c256338",
      "b9b9e2f159f94a348ec2ba2644c72a9f",
      "3bfc2f271bf742bda2f12dd1c44305be",
      "ae10000a3c12476fa6a0e8311636a38f",
      "52c884bc6e024300ac6ea9df48d42044",
      "0d07543cf001478486e856f0bdec23dc",
      "eaeee59d4205429d85f5699ce2f3fc43",
      "3511e8fcc4a14af2a257cb68d7326175",
      "ed5c76cf3e1a4eb9b52a455549202575",
      "e8cbfeb8f2734e98a2f1fe4ecdc25fae",
      "788ad675450048a8b24f588fdd8889e5",
      "e4811029bf5747098cc7db06052222bd",
      "24a667f23fba4486a3e264e00466ec5b",
      "02669c07d34a47b3af09be86d731a846",
      "9c68750b80664d7da4af852ba82bf42a",
      "88b93213b58d485785321888e69cb507",
      "35a7ef1af4854ab9aea5f3e90ada64f3",
      "13cd40707de2468d96785245b4ec2435",
      "82de6dfc989d42c09ff7d137bf8a35bc",
      "b149c4a9076f403196aa1344b67f9371",
      "078ce4d003b2496083f432f78d550d64",
      "d5501b82f4c747dfae7bd3076b31a2b7",
      "ad7ece3e45ab4900ae268dd43561234b",
      "336c0b99a7234f648a7430a8974c422d",
      "fe6eb3d8ebaa41b499ddd872d5c4c5ac",
      "075c208d784441ef957e254fa43c894e",
      "9b349fa78e5e466a8b754c5602c1360c",
      "30f98f9353b94f888848bd1d25dcb9b0",
      "9e87f55810214939a73b5f7db80e9a13",
      "0c574cd77f504b8c9bd8f95a674fd00a",
      "5d10e799da23449888a37959b257cb55",
      "1e73d875005f4e6d8d8dc2d3df989d1b",
      "cc461a5af9e447da88544a17045a8d42",
      "63ee4dd9dcf84aa08243881bcaf723ba",
      "25d5679976364c1e9327139b0ba3fa60",
      "5d403a527a894f34b0cdee7e32c0b41a",
      "c060345dda05446eb5a682827597abaa"
     ]
    },
    "id": "tBu79ZgcjZj4",
    "outputId": "f92d5d2c-e064-480d-a7a9-e812394e4626"
   },
   "outputs": [],
   "source": [
    "print(\"\\nStarting Experiment: config3\")\n",
    "config3 = experiment_configs[0]\n",
    "model_config3 = BartForConditionalGeneration.from_pretrained(model_checkpoint)\n",
    "training_args_config3 = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"multinews_bart_base_{config3['name']}\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=config3[\"train_batch_size\"],\n",
    "    per_device_eval_batch_size=config3[\"train_batch_size\"],\n",
    "    learning_rate=config3[\"learning_rate\"],\n",
    "    num_train_epochs=config3[\"num_train_epochs\"],\n",
    "    bf16=True,\n",
    "    logging_dir=f'./logs_{config3[\"name\"]}',\n",
    "    logging_steps=50,\n",
    "    predict_with_generate=True,\n",
    "    report_to=[],\n",
    ")\n",
    "trainer_config3 = CustomSeq2SeqTrainer(\n",
    "    model=model_config3,\n",
    "    args=training_args_config3,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "trainer_config3.train()\n",
    "trainer_config3.save_pretrained(\"./multinews_model\")\n",
    "tokenizer.save_pretrained(\"./multinews_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YUMSxmoR5R_i",
    "outputId": "9ce99980-1e2d-48e8-baf0-dca471ce4de9"
   },
   "outputs": [],
   "source": [
    "trainer_config3.model.save_pretrained(\"./multinews_model\")\n",
    "tokenizer.save_pretrained(\"./multinews_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "sAzD326bjhTv",
    "outputId": "5364a20e-9059-40d9-8164-5340b241b6cf"
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "eval_losses = []\n",
    "for log in trainer_config3.state.log_history:\n",
    "    if \"loss\" in log:\n",
    "        train_losses.append(log[\"loss\"])\n",
    "    if \"eval_loss\" in log:\n",
    "        eval_losses.append(log[\"eval_loss\"])\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(range(len(train_losses), len(train_losses) + len(eval_losses)), eval_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Logging Steps\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss for config3\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "lXNTEZFBjkYH",
    "outputId": "5b143cc1-77a0-4281-bc9f-905f049cb542"
   },
   "outputs": [],
   "source": [
    "eval_results_config3 = trainer_config3.evaluate(eval_dataset=tokenized_datasets[\"validation\"])\n",
    "print(f\"Validation results for config3:\")\n",
    "print(eval_results_config3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "x9Mt_4iPcM9m",
    "outputId": "196a6a5b-8d32-470f-f680-f0a8f4f50fe4"
   },
   "outputs": [],
   "source": [
    "test_metrics = trainer_config3.evaluate(eval_dataset=tokenized_datasets[\"test\"].select(range(100)))\n",
    "print(\"Test metrics for Multi-News config3:\")\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "HPzZe95Flrj_",
    "outputId": "a39743a1-fa89-43d0-a02a-72f74cc172fa"
   },
   "outputs": [],
   "source": [
    "metrics_to_plot = {\n",
    "    \"ROUGE-1\": test_metrics[\"eval_rouge1\"] * 100,\n",
    "    \"ROUGE-2\": test_metrics[\"eval_rouge2\"] * 100,\n",
    "    \"ROUGE-L\": test_metrics[\"eval_rougeL\"] * 100,\n",
    "    \"BLEU\": test_metrics[\"eval_bleu\"],\n",
    "    \"BERTScore\": test_metrics[\"eval_bertscore\"] * 100,\n",
    "}\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(list(metrics_to_plot.keys()), list(metrics_to_plot.values()))\n",
    "plt.title(\"Test Metrics (%) for Best Model\")\n",
    "plt.xlabel(\"Metric\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code of app.py that I used to deploy on hugging face. The below cell won't work as it's for gradio on hugging face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "model_path = \"./multinews_model\" \n",
    "model = BartForConditionalGeneration.from_pretrained(model_path)\n",
    "tokenizer = BartTokenizer.from_pretrained(model_path)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.to(\"cuda\")\n",
    "model.eval()\n",
    "\n",
    "def summarize(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "    summary_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_length=256,\n",
    "        num_beams=8,\n",
    "        length_penalty=1.5,\n",
    "        no_repeat_ngram_size=3,\n",
    "        min_length=50,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=summarize,\n",
    "    inputs=gr.Textbox(lines=10, label=\"Enter Text to Summarize\"),\n",
    "    outputs=gr.Textbox(label=\"Summary\"),\n",
    "    title=\"Multi-News Summarization\",\n",
    "    description=\"Enter a news article to get a summary generated by the fine-tuned BART model.\"\n",
    ")\n",
    "\n",
    "interface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-News Config3 Training & Evaluation\n",
    "\n",
    "**Data Prep & Tokenization:**  \n",
    "- We have loaded the Multi-News dataset (using \"document\" and \"summary\" columns) then created train/validation/test splits, and tokenized texts (max 1024 tokens) and summaries (max 256 tokens).\n",
    "\n",
    "**Model Fine-Tuning:**  \n",
    "- We have fine-tuned the facebook/bart-base model using config3 (LR = 5e-5, batch size = 4, 3 epochs) with a custom trainer.\n",
    "\n",
    "**Evaluation Metrics (Epoch 3 & Test):**  \n",
    "  - **Final Training Loss:** 2.43  \n",
    "  - **Validation Loss:** 2.62  \n",
    "  - **Rouge-1:** 0.42, **Rouge-2:** 0.14, **Rouge-L:** 0.21  \n",
    "  - **BLEU:** 17.48  \n",
    "  - **BERTScore:** 0.89\n",
    "\n",
    "**Observations:**\n",
    "- The loss was decreased which means model is learning without overfitting.\n",
    "- Here, lower ROUGE scores compared to Billsum are due to the Multi-News dataset's higher complexity (longer, multi-document inputs, and diverse writing styles).\n",
    "- Here, high BLEU and BERTScore shows that, the model still generates coherent and sementically accurate summaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- alexfabbri/multinews on Hugging Face: https://huggingface.co/datasets/alexfabbri/multi_news\n",
    "- Facebook/bart-base on Hugging Face: https://huggingface.co/facebook/bart-base\n",
    "- Transformers Documentation: https://huggingface.co/docs/transformers/ \n",
    "- Datasets Documentation: https://huggingface.co/docs/datasets/\n",
    "- rouge_score: https://huggingface.co/spaces/evaluate-metric/rouge\n",
    "- sacreBLEU: https://pypi.org/project/sacreBLEU/\n",
    "- BLEU: https://huggingface.co/spaces/evaluate-metric/bleu  \n",
    "- bert_score: https://huggingface.co/spaces/evaluate-metric/bertscore\n",
    "- Python os module Documentation: https://docs.python.org/3/library/os.html\n",
    "- Python random module Documentation: https://docs.python.org/3/library/random.html\n",
    "- NumPy Documentation: https://numpy.org/doc/stable/user/index.html#user\n",
    "- PyTorch Documentation: https://pytorch.org/docs/stable/index.html\n",
    "- Matplotlib Documentation: https://matplotlib.org/stable/users/index.html\n",
    "- Hugging Face Evaluate Documentation: https://huggingface.co/docs/evaluate/\n",
    "- Gradio: https://www.gradio.app/docs"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
