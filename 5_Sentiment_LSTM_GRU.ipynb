{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "75vL9JzGiKYc",
    "outputId": "00727a03-02ba-406f-e23a-7451158b6797"
   },
   "outputs": [],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fcy0__FRhKnh",
    "outputId": "6e813f48-2d1f-430d-f578-e40b94fb52f4"
   },
   "outputs": [],
   "source": [
    "\n",
    "!pip install torchtext==0.17.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6D_6q67dijJT",
    "outputId": "eb607627-8c2f-48dd-a2c9-aa31694afe57"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GwDfE1-AbiqY"
   },
   "outputs": [],
   "source": [
    "import os, tarfile, time, numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator, GloVe\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vjKnyhk0a2v_",
    "outputId": "92558eea-fd60-4481-b161-06618bf09d91"
   },
   "outputs": [],
   "source": [
    "!pip install wordcloud\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1v_JNYx8bFmQ"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "sns.set(style=\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DQ0CvyCkbHvy",
    "outputId": "8f599b27-a6e7-4309-891f-947d7e7c3304"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dOSH2IC7bO9M",
    "outputId": "0a6c7275-70e7-4e1e-b219-87b625065a1f"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"aclImdb_v1.tar.gz\"):\n",
    "    !wget -O aclImdb_v1.tar.gz http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "\n",
    "if not os.path.exists(\"aclImdb\"):\n",
    "    with tarfile.open(\"aclImdb_v1.tar.gz\", \"r:gz\") as tar:\n",
    "        tar.extractall()\n",
    "\n",
    "print(\"Dataset downloaded and extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wEQjzUUubQ9l"
   },
   "outputs": [],
   "source": [
    "def load_imdb_data(dir_path):\n",
    "    texts, labels = [], []\n",
    "    for sentiment in ['pos', 'neg']:\n",
    "        sentiment_dir = os.path.join(dir_path, sentiment)\n",
    "        for filename in os.listdir(sentiment_dir):\n",
    "            if filename.endswith(\".txt\"):\n",
    "                with open(os.path.join(sentiment_dir, filename), encoding=\"utf-8\") as f:\n",
    "                    texts.append(f.read())\n",
    "                    labels.append(1 if sentiment == 'pos' else 0)\n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "itFpE8VibUsp",
    "outputId": "1af273c7-728e-4364-bca8-b448e724dc35"
   },
   "outputs": [],
   "source": [
    "train_texts, train_labels = load_imdb_data(os.path.join(\"aclImdb\", \"train\"))\n",
    "test_texts, test_labels = load_imdb_data(os.path.join(\"aclImdb\", \"test\"))\n",
    "\n",
    "train_df = pd.DataFrame({'review': train_texts, 'sentiment': train_labels})\n",
    "test_df  = pd.DataFrame({'review': test_texts,  'sentiment': test_labels})\n",
    "\n",
    "print(\"Train data shape:\", train_df.shape)\n",
    "print(\"Test data shape:\", test_df.shape)\n",
    "print(\"First 5 rows of training data:\")\n",
    "print(train_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0bsN7v9Ub9Ds"
   },
   "source": [
    "This is IMDb Large Movie Review Dataset, which contains 25,000 movie reviews for training and 25,000 for testing.\n",
    "Each review is labeled as positive (1) or negative (0), and the data is provided by Stanford.\n",
    "Source: https://ai.stanford.edu/~amaas/data/sentiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IAFa9OOpcGTV",
    "outputId": "3f70d1a9-0b0c-4d4a-96be-5485664f0c46"
   },
   "outputs": [],
   "source": [
    "print(\"Number of training samples:\", len(train_df))\n",
    "print(\"Number of test samples:\", len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jzpokUQNcG9y",
    "outputId": "e1f692f6-103e-4d7b-cf71-ccc0a3263744"
   },
   "outputs": [],
   "source": [
    "class_counts = train_df['sentiment'].value_counts(normalize=True) * 100\n",
    "print(\"Class distribution (percentage):\\n\", class_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wS8yCehjcQaQ",
    "outputId": "38a06778-6669-4280-f543-c168dbc70897"
   },
   "outputs": [],
   "source": [
    "train_df['word_count'] = train_df['review'].apply(lambda x: len(x.split()))\n",
    "train_df['char_count'] = train_df['review'].apply(len)\n",
    "print(\"Average word count:\", train_df['word_count'].mean())\n",
    "print(\"Average character count:\", train_df['char_count'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M05DFTeydLSJ",
    "outputId": "1f7ca699-27e7-4fa5-ad8e-f096a3cae4cd"
   },
   "outputs": [],
   "source": [
    "print(\"Missing values in training set:\\n\", train_df.isnull().sum())\n",
    "train_df = train_df.dropna()\n",
    "test_df = test_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "id": "waADt1cVdPbS",
    "outputId": "43bb17a5-8727-460b-9f9b-bcd740ac2e90"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(train_df['word_count'], bins=50, kde=True)\n",
    "plt.title(\"Histogram of Review Lengths (Words)\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(train_df['char_count'], bins=50, kde=True)\n",
    "plt.title(\"Histogram of Review Lengths (Characters)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 871
    },
    "id": "DmgE5zLnda7L",
    "outputId": "1aca7d30-4c45-46b6-887e-ff99e8f425f5"
   },
   "outputs": [],
   "source": [
    "def generate_wordcloud(text, title):\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "pos_text = \" \".join(train_df[train_df['sentiment']==1]['review'].tolist())\n",
    "neg_text = \" \".join(train_df[train_df['sentiment']==0]['review'].tolist())\n",
    "generate_wordcloud(pos_text, \"Word Cloud for Positive Reviews\")\n",
    "generate_wordcloud(neg_text, \"Word Cloud for Negative Reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "1Lcccxz2dtXZ",
    "outputId": "36866a9c-410b-45ae-e57a-b4213401246b"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='sentiment', data=train_df, color='burlywood')\n",
    "plt.title(\"Number of Reviews for Each Sentiment Class\")\n",
    "plt.xticks([0, 1], [\"Negative\", \"Positive\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 695
    },
    "id": "U4L-1b_3d7Al",
    "outputId": "7c751b9b-3179-436e-9829-f21935265057"
   },
   "outputs": [],
   "source": [
    "from nltk import ngrams, FreqDist\n",
    "\n",
    "all_tokens = []\n",
    "for review in train_df['review']:\n",
    "    all_tokens.extend((get_tokenizer(\"basic_english\"))(review))\n",
    "\n",
    "bigrams = list(ngrams(all_tokens, 2))\n",
    "bigram_freq = FreqDist(bigrams)\n",
    "\n",
    "common_bigrams = bigram_freq.most_common(20)\n",
    "print(\"Top 20 bigrams:\", common_bigrams)\n",
    "\n",
    "bigram_labels = [' '.join(bigram) for bigram, count in common_bigrams]\n",
    "counts = [count for bigram, count in common_bigrams]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=counts, y=bigram_labels, palette=\"viridis\")\n",
    "plt.title(\"Top 20 Most Common Bigrams\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Bigrams\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uc921wP3fKZO",
    "outputId": "6614fa23-7591-4d5a-fb2a-c8889a16afe4"
   },
   "outputs": [],
   "source": [
    "sample_review = train_df['review'].iloc[0]\n",
    "\n",
    "start = time.time()\n",
    "tokens_nltk = word_tokenize(sample_review)\n",
    "nltk_time = time.time() - start\n",
    "print(\"nltk.word_tokenize time:\", nltk_time, \"seconds\")\n",
    "\n",
    "basic_tokenizer = get_tokenizer(\"basic_english\")\n",
    "start = time.time()\n",
    "tokens_basic = basic_tokenizer(sample_review)\n",
    "basic_time = time.time() - start\n",
    "print(\"basic_english tokenizer time:\", basic_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Plsce77BezXi",
    "outputId": "f2547d25-0fea-4783-8fb6-661ad9bde84b"
   },
   "outputs": [],
   "source": [
    "tokenizer = basic_tokenizer\n",
    "\n",
    "def yield_tokens(data_iter, tokenizer):\n",
    "    for text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_df['review'], tokenizer), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "print(\"Vocabulary size:\", len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SrYqRNRThJmC",
    "outputId": "2d883a68-f82f-4233-9a1a-bb987467d928"
   },
   "outputs": [],
   "source": [
    "def text_to_sequence(text, tokenizer, vocab):\n",
    "    return [vocab[token] for token in tokenizer(text)]\n",
    "\n",
    "train_df['seq'] = train_df['review'].apply(lambda x: text_to_sequence(x, tokenizer, vocab))\n",
    "test_df['seq'] = test_df['review'].apply(lambda x: text_to_sequence(x, tokenizer, vocab))\n",
    "\n",
    "lengths = train_df['seq'].apply(len)\n",
    "max_length = int(np.percentile(lengths, 95))\n",
    "print(\"Max sequence length (95th percentile):\", max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_CMG1m5egcvf",
    "outputId": "7010e9e1-5e0f-4a2c-ae6f-0f8ecca6b16c"
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "train_tensors = [torch.tensor(seq[:max_length], dtype=torch.long) for seq in train_df['seq']]\n",
    "test_tensors  = [torch.tensor(seq[:max_length], dtype=torch.long) for seq in test_df['seq']]\n",
    "\n",
    "padded_train = pad_sequence(train_tensors, batch_first=True, padding_value=0)\n",
    "padded_test  = pad_sequence(test_tensors, batch_first=True, padding_value=0)\n",
    "\n",
    "def ensure_fixed_length(tensor, target_length):\n",
    "    if tensor.size(1) < target_length:\n",
    "        pad_size = target_length - tensor.size(1)\n",
    "        extra_pad = torch.zeros(tensor.size(0), pad_size, dtype=torch.long)\n",
    "        tensor = torch.cat([tensor, extra_pad], dim=1)\n",
    "    return tensor[:, :target_length]\n",
    "\n",
    "padded_train = ensure_fixed_length(padded_train, max_length)\n",
    "padded_test = ensure_fixed_length(padded_test, max_length)\n",
    "\n",
    "train_df['padded_seq'] = padded_train.tolist()\n",
    "test_df['padded_seq'] = padded_test.tolist()\n",
    "\n",
    "print(\"All sequences have been padded/truncated to length:\", max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Civ0Gqgtfki5",
    "outputId": "686bbf2e-8beb-4c7a-bd3d-d459e803ea2a"
   },
   "outputs": [],
   "source": [
    "def text_to_sequence(text, tokenizer, vocab):\n",
    "    return [vocab[token] for token in tokenizer(text)]\n",
    "\n",
    "train_df['seq'] = train_df['review'].apply(lambda x: text_to_sequence(x, tokenizer, vocab))\n",
    "test_df['seq'] = test_df['review'].apply(lambda x: text_to_sequence(x, tokenizer, vocab))\n",
    "\n",
    "lengths = train_df['seq'].apply(len)\n",
    "max_length = int(np.percentile(lengths, 95))\n",
    "print(\"Max sequence length (95th percentile):\", max_length)\n",
    "\n",
    "def pad_sequence_fn(seq, max_length):\n",
    "    if len(seq) < max_length:\n",
    "        return seq + [0]*(max_length - len(seq))\n",
    "    else:\n",
    "        return seq[:max_length]\n",
    "\n",
    "train_df['padded_seq'] = train_df['seq'].apply(lambda x: pad_sequence_fn(x, max_length))\n",
    "test_df['padded_seq'] = test_df['seq'].apply(lambda x: pad_sequence_fn(x, max_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding and truncation are important preprocessing steps when we are working with variable-length text inputs for sequence models, and they can have significant impacts on model performance:\n",
    "\n",
    "1. Truncation: Here, the issue is that, when the sequences longer than a chosen maximum length are truncated we might loose important information. This happen specially if key context or details occur later in the text. Now, this loss of information can negatively affect the model's ability to understand or correctly classify a review. But truncation is necessary to control computational complexity and ensure consistent input sizes.\n",
    "\n",
    "2. Paddidng: If we padd sequence with zero than, it will ensure that all the sequences are of uniform length and it is necessary for efficient batch processing. But too much padding can introduce a lot of non-informative tokens into the model input. So, it can led to more use of computational power unnecessarily or might leads to overfit.\n",
    "\n",
    "3. Balance: Setting the maximum sequence length like 95 percentile will leads to preservation of most sequences and also avoid excessive truncation. So, this minimizes the risk of losing critical information and also limit the amount of padding needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "25UvX0H2hwus"
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AbwIcINDh9a7"
   },
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.sequences = df['padded_seq'].tolist()\n",
    "        self.labels = df['sentiment'].tolist()\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.sequences[idx], dtype=torch.long), torch.tensor(self.labels[idx], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7t3M-gKAiBwh"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataset = SentimentDataset(train_data)\n",
    "val_dataset   = SentimentDataset(val_data)\n",
    "test_dataset  = SentimentDataset(test_df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BbdOYCd5m2QC",
    "outputId": "91be6e02-5270-4478-c93f-74790d4dbd5a"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "\n",
    "class BaselineLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers, num_classes, dropout):\n",
    "        super(BaselineLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers,\n",
    "                            dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        out = self.fc(lstm_out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embed_dim = 100\n",
    "hidden_dim = 128\n",
    "num_layers = 3\n",
    "num_classes = 2\n",
    "dropout = 0.5\n",
    "\n",
    "model = BaselineLSTM(vocab_size, embed_dim, hidden_dim, num_layers, num_classes, dropout)\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"Baseline LSTM Model Summary:\")\n",
    "sample_input = torch.randint(0, vocab_size, (batch_size, max_length), dtype=torch.long, device=device)\n",
    "summary(model, input_data=sample_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WW13Dnh8oSt9"
   },
   "outputs": [],
   "source": [
    "def train_evaluate_model(hidden_dim, num_layers, dropout, learning_rate, num_epochs=5):\n",
    "    model_exp = BaselineLSTM(vocab_size, embed_dim, hidden_dim, num_layers, num_classes, dropout).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model_exp.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model_exp.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model_exp(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_train_acc = correct_train / total_train\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        train_accuracies.append(epoch_train_acc)\n",
    "\n",
    "        model_exp.eval()\n",
    "        running_val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model_exp(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "        epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "        epoch_val_acc = correct_val / total_val\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        val_accuracies.append(epoch_val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss={epoch_train_loss:.4f}, Train Acc={epoch_train_acc:.4f}, \" \\\n",
    "              f\"Val Loss={epoch_val_loss:.4f}, Val Acc={epoch_val_acc:.4f}\")\n",
    "\n",
    "    model_exp.eval()\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model_exp(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "    test_acc = correct_test / total_test\n",
    "\n",
    "    return model_exp, epoch_val_acc, test_acc, train_losses, val_losses, train_accuracies, val_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p0YglUq-FK3l"
   },
   "outputs": [],
   "source": [
    "experiment_results = []\n",
    "best_val_acc = 0.0\n",
    "best_model = None\n",
    "best_config = None\n",
    "best_metrics = {}\n",
    "\n",
    "exp_configs = [\n",
    "    {\n",
    "        \"name\": \"Exp1\",\n",
    "        \"hidden_dim\": 128,\n",
    "        \"num_layers\": 3,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"dropouts\": [0.3, 0.5]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Exp2\",\n",
    "        \"hidden_dim\": 256,\n",
    "        \"num_layers\": 3,\n",
    "        \"learning_rate\": 0.002,\n",
    "        \"dropouts\": [0.3, 0.5]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Exp3\",\n",
    "        \"hidden_dim\": 128,\n",
    "        \"num_layers\": 4,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"dropouts\": [0.3, 0.5]\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FhCScUIbO1Pf"
   },
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QG4-3kRdFW1u",
    "outputId": "5cca57e5-660a-49ad-8640-92f027d39dbe"
   },
   "outputs": [],
   "source": [
    "print(\"Starting experiments...\\n\")\n",
    "for config in exp_configs:\n",
    "    for dropout_val in config[\"dropouts\"]:\n",
    "        print(f\"Running {config['name']} with hidden_dim={config['hidden_dim']}, num_layers={config['num_layers']}, \"\n",
    "              f\"learning_rate={config['learning_rate']}, dropout={dropout_val}\")\n",
    "        model_exp, val_acc, test_acc, t_losses, v_losses, t_accs, v_accs = train_evaluate_model(\n",
    "            hidden_dim=config[\"hidden_dim\"],\n",
    "            num_layers=config[\"num_layers\"],\n",
    "            dropout=dropout_val,\n",
    "            learning_rate=config[\"learning_rate\"],\n",
    "            num_epochs=5\n",
    "        )\n",
    "        print(f\"Result: Val Acc={val_acc:.4f}, Test Acc={test_acc:.4f}\\n\")\n",
    "        experiment_results.append({\n",
    "            \"Experiment\": config[\"name\"],\n",
    "            \"Hidden_dim\": config[\"hidden_dim\"],\n",
    "            \"Num_layers\": config[\"num_layers\"],\n",
    "            \"Learning_rate\": config[\"learning_rate\"],\n",
    "            \"Dropout\": dropout_val,\n",
    "            \"Val_Acc\": val_acc,\n",
    "            \"Test_Acc\": test_acc\n",
    "        })\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model = copy.deepcopy(model_exp)\n",
    "            best_config = {\n",
    "                \"Experiment\": config[\"name\"],\n",
    "                \"Hidden_dim\": config[\"hidden_dim\"],\n",
    "                \"Num_layers\": config[\"num_layers\"],\n",
    "                \"Learning_rate\": config[\"learning_rate\"],\n",
    "                \"Dropout\": dropout_val,\n",
    "                \"Val_Acc\": val_acc,\n",
    "                \"Test_Acc\": test_acc\n",
    "            }\n",
    "            best_metrics = {\n",
    "                \"train_losses\": t_losses,\n",
    "                \"val_losses\": v_losses,\n",
    "                \"train_accuracies\": t_accs,\n",
    "                \"val_accuracies\": v_accs\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WI0GeXVvFc_8",
    "outputId": "ecac358a-584c-4faf-9c5f-9fc9d827406f"
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(experiment_results)\n",
    "print(\"\\nSummary of Experiment Results:\")\n",
    "print(results_df)\n",
    "print(\"\\nBest Model Configuration:\")\n",
    "print(best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YkxuTmCAFhvl",
    "outputId": "850ab8ba-d958-4e50-917d-5450d832db07"
   },
   "outputs": [],
   "source": [
    "best_model.eval()\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = best_model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "print(\"Classification Report for Best Model:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=[\"Negative\", \"Positive\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "id": "Nbya5aVgFsqT",
    "outputId": "ad672fb1-c486-4c75-e0ba-a429d666a5f5"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Greens\",\n",
    "            xticklabels=[\"Negative\", \"Positive\"],\n",
    "            yticklabels=[\"Negative\", \"Positive\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix for Best Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "b8Fv8lj9FxNK",
    "outputId": "05214828-76ef-4a05-b3d5-eff3d86795e0"
   },
   "outputs": [],
   "source": [
    "plt.plot(best_metrics[\"train_losses\"], marker='o', label=\"Train Loss\")\n",
    "plt.plot(best_metrics[\"val_losses\"], marker='o', label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs. Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "hBHUpiQJFxzq",
    "outputId": "3c493a07-50e0-4a28-e58f-e7aaa7cf744f"
   },
   "outputs": [],
   "source": [
    "plt.plot(best_metrics[\"train_accuracies\"], marker='o', label=\"Train Accuracy\")\n",
    "plt.plot(best_metrics[\"val_accuracies\"], marker='o', label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training vs. Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l1FaSp3YF5Je",
    "outputId": "e196fc34-b726-408b-b062-c4703f34dc8a"
   },
   "outputs": [],
   "source": [
    "torch.save(best_model.state_dict(), \"best_baseline_lstm.pth\")\n",
    "print(\"Best model weights saved as 'best_baseline_lstm.pth'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wqUH8Io_VqAT"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2XYXA-S1IFy2",
    "outputId": "8fabb8d6-09fa-496f-bfd7-3540e3162e22"
   },
   "outputs": [],
   "source": [
    "with open(\"best_training_metrics.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_metrics, f)\n",
    "print(\"Best model training metrics saved as 'best_training_metrics.pkl'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gKK0tKeKL7H"
   },
   "source": [
    "**Improved**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JZOS5yoEKLZk",
    "outputId": "2ad6ac6d-bfaa-46f8-ffba-75043ae18a9b"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchtext.vocab import GloVe\n",
    "from torchinfo import summary\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attn = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, outputs):\n",
    "        attn_scores = self.attn(outputs)\n",
    "        attn_weights = torch.softmax(attn_scores, dim=1)\n",
    "        context = torch.sum(attn_weights * outputs, dim=1)\n",
    "        return context, attn_weights\n",
    "\n",
    "glove = GloVe(name='6B', dim=100)\n",
    "\n",
    "embedding_matrix = torch.randn(vocab_size, embed_dim)\n",
    "for token, idx in vocab.get_stoi().items():\n",
    "    if token in glove.stoi:\n",
    "        embedding_matrix[idx] = glove.vectors[glove.stoi[token]]\n",
    "\n",
    "class ImprovedGRUAttentionModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers, num_classes, dropout, embedding_matrix):\n",
    "        super(ImprovedGRUAttentionModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.embedding.weight.data.copy_(embedding_matrix)\n",
    "        self.embedding.weight.requires_grad = False\n",
    "\n",
    "        self.gru = nn.GRU(embed_dim, hidden_dim, num_layers=num_layers,\n",
    "                          dropout=dropout, batch_first=True, bidirectional=True)\n",
    "        self.attention = Attention(hidden_dim * 2)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        gru_out, _ = self.gru(embedded)\n",
    "        context, attn_weights = self.attention(gru_out)\n",
    "        out = self.fc(context)\n",
    "        return out, attn_weights\n",
    "\n",
    "\n",
    "hidden_dim_adv = 128\n",
    "num_layers_adv = 4\n",
    "dropout_adv = 0.5\n",
    "\n",
    "advanced_model = ImprovedGRUAttentionModel(vocab_size, embed_dim, hidden_dim_adv, num_layers_adv, num_classes, dropout_adv, embedding_matrix)\n",
    "advanced_model = advanced_model.to(device)\n",
    "\n",
    "print(\"Advanced Improved Model (GRU with Attention) Summary:\")\n",
    "sample_input = torch.randint(0, vocab_size, (batch_size, max_length), dtype=torch.long, device=device)\n",
    "summary(advanced_model, input_data=sample_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HthwPmXPKjWW"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def train_evaluate_advanced_model(hidden_dim, num_layers, dropout, learning_rate, num_epochs=5):\n",
    "    model_exp = ImprovedGRUAttentionModel(vocab_size, embed_dim, hidden_dim, num_layers, num_classes, dropout, embedding_matrix).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model_exp.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model_exp.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train, total_train = 0, 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = model_exp(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_train_acc = correct_train / total_train\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        train_accuracies.append(epoch_train_acc)\n",
    "\n",
    "        model_exp.eval()\n",
    "        running_val_loss = 0.0\n",
    "        correct_val, total_val = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs, _ = model_exp(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "        epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "        epoch_val_acc = correct_val / total_val\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        val_accuracies.append(epoch_val_acc)\n",
    "\n",
    "        print(f\"[Advanced] Epoch {epoch+1}/{num_epochs}: Train Loss={epoch_train_loss:.4f}, Train Acc={epoch_train_acc:.4f}, \" \\\n",
    "              f\"Val Loss={epoch_val_loss:.4f}, Val Acc={epoch_val_acc:.4f}\")\n",
    "\n",
    "    model_exp.eval()\n",
    "    correct_test, total_test = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs, _ = model_exp(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "    test_acc = correct_test / total_test\n",
    "\n",
    "    return model_exp, epoch_val_acc, test_acc, train_losses, val_losses, train_accuracies, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AU9Og4VfLHnt"
   },
   "outputs": [],
   "source": [
    "advanced_experiment_results = []\n",
    "best_val_acc_adv = 0.0\n",
    "best_model_adv = None\n",
    "best_config_adv = None\n",
    "best_metrics_adv = {}\n",
    "\n",
    "exp_configs_adv = [\n",
    "    {\n",
    "        \"name\": \"AdvExp1\",\n",
    "        \"hidden_dim\": 128,\n",
    "        \"num_layers\": 4,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"dropouts\": [0.3, 0.5]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"AdvExp2\",\n",
    "        \"hidden_dim\": 128,\n",
    "        \"num_layers\": 4,\n",
    "        \"learning_rate\": 0.002,\n",
    "        \"dropouts\": [0.3, 0.5]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"AdvExp3\",\n",
    "        \"hidden_dim\": 256,\n",
    "        \"num_layers\": 4,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"dropouts\": [0.3, 0.5]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CVzZZldQLLS2",
    "outputId": "81625cf7-6fa4-4ac9-e6de-e5ee8980b90a"
   },
   "outputs": [],
   "source": [
    "print(\"Starting Advanced Model Experiments...\\n\")\n",
    "for config in exp_configs_adv:\n",
    "    for dropout_val in config[\"dropouts\"]:\n",
    "        print(f\"Running {config['name']} with hidden_dim={config['hidden_dim']}, num_layers={config['num_layers']}, \"\n",
    "              f\"learning_rate={config['learning_rate']}, dropout={dropout_val}\")\n",
    "        model_exp, val_acc, test_acc, t_losses, v_losses, t_accs, v_accs = train_evaluate_advanced_model(\n",
    "            hidden_dim=config[\"hidden_dim\"],\n",
    "            num_layers=config[\"num_layers\"],\n",
    "            dropout=dropout_val,\n",
    "            learning_rate=config[\"learning_rate\"],\n",
    "            num_epochs=5\n",
    "        )\n",
    "        print(f\"Result: Val Acc={val_acc:.4f}, Test Acc={test_acc:.4f}\\n\")\n",
    "        advanced_experiment_results.append({\n",
    "            \"Experiment\": config[\"name\"],\n",
    "            \"Hidden_dim\": config[\"hidden_dim\"],\n",
    "            \"Num_layers\": config[\"num_layers\"],\n",
    "            \"Learning_rate\": config[\"learning_rate\"],\n",
    "            \"Dropout\": dropout_val,\n",
    "            \"Val_Acc\": val_acc,\n",
    "            \"Test_Acc\": test_acc\n",
    "        })\n",
    "        if val_acc > best_val_acc_adv:\n",
    "            best_val_acc_adv = val_acc\n",
    "            best_model_adv = copy.deepcopy(model_exp)\n",
    "            best_config_adv = {\n",
    "                \"Experiment\": config[\"name\"],\n",
    "                \"Hidden_dim\": config[\"hidden_dim\"],\n",
    "                \"Num_layers\": config[\"num_layers\"],\n",
    "                \"Learning_rate\": config[\"learning_rate\"],\n",
    "                \"Dropout\": dropout_val,\n",
    "                \"Val_Acc\": val_acc,\n",
    "                \"Test_Acc\": test_acc\n",
    "            }\n",
    "            best_metrics_adv = {\n",
    "                \"train_losses\": t_losses,\n",
    "                \"val_losses\": v_losses,\n",
    "                \"train_accuracies\": t_accs,\n",
    "                \"val_accuracies\": v_accs\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XDPuwT8ELOMx",
    "outputId": "c007407a-e541-4dac-b38b-6265d26b74ec"
   },
   "outputs": [],
   "source": [
    "results_df_adv = pd.DataFrame(advanced_experiment_results)\n",
    "print(\"\\nSummary of Advanced Model Experiment Results:\")\n",
    "print(results_df_adv)\n",
    "print(\"\\nBest Advanced Model Configuration:\")\n",
    "print(best_config_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 720
    },
    "id": "WwNwrzehLP1_",
    "outputId": "92693f38-61e0-4a86-fc16-f22564ab30ee"
   },
   "outputs": [],
   "source": [
    "best_model_adv.eval()\n",
    "all_labels_adv = []\n",
    "all_preds_adv = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs, _ = best_model_adv(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_labels_adv.extend(labels.cpu().numpy())\n",
    "        all_preds_adv.extend(predicted.cpu().numpy())\n",
    "\n",
    "print(\"Classification Report for Best Advanced Model:\")\n",
    "print(classification_report(all_labels_adv, all_preds_adv, target_names=[\"Negative\", \"Positive\"]))\n",
    "\n",
    "cm_adv = confusion_matrix(all_labels_adv, all_preds_adv)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm_adv, annot=True, fmt=\"d\", cmap=\"Greens\",\n",
    "            xticklabels=[\"Negative\", \"Positive\"],\n",
    "            yticklabels=[\"Negative\", \"Positive\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix for Best Advanced Model\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "QhB5C--2LUyo",
    "outputId": "95e18b26-b367-4525-9882-b3fc4738e637"
   },
   "outputs": [],
   "source": [
    "plt.plot(best_metrics_adv[\"train_losses\"], marker='o', label=\"Train Loss\")\n",
    "plt.plot(best_metrics_adv[\"val_losses\"], marker='o', label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Advanced Model: Training vs. Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "8Icq878OLkLB",
    "outputId": "ce72efe2-9635-4a72-f226-0f8b7046b286"
   },
   "outputs": [],
   "source": [
    "plt.plot(best_metrics_adv[\"train_accuracies\"], marker='o', label=\"Train Accuracy\")\n",
    "plt.plot(best_metrics_adv[\"val_accuracies\"], marker='o', label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Advanced Model: Training vs. Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kebJmYx-Lo8f",
    "outputId": "4efc2cbe-4c71-40dd-ba49-0ea74ffe47c2"
   },
   "outputs": [],
   "source": [
    "torch.save(best_model_adv.state_dict(), \"best_advanced_gru_attention.pth\")\n",
    "print(\"Best advanced model weights saved as 'best_advanced_gru_attention.pth'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dOBgWhUFLqnR",
    "outputId": "29159f08-26ea-49c9-9cd1-81d42458b00d"
   },
   "outputs": [],
   "source": [
    "with open(\"best_training_metrics_adv.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_metrics_adv, f)\n",
    "print(\"Best model training metrics saved as 'best_training_metrics_adv.pkl'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "id": "2XGcGXyYMAvK",
    "outputId": "fc4119e0-97ce-43ff-d7a8-af8fc5c48ea7"
   },
   "outputs": [],
   "source": [
    "with open(\"best_training_metrics.pkl\", \"rb\") as f:\n",
    "    baseline_metrics = pickle.load(f)\n",
    "\n",
    "with open(\"best_training_metrics_adv.pkl\", \"rb\") as f:\n",
    "    improved_metrics = pickle.load(f)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(baseline_metrics[\"train_losses\"], marker='o', label=\"Baseline Train Loss\")\n",
    "plt.plot(baseline_metrics[\"val_losses\"], marker='o', label=\"Baseline Val Loss\")\n",
    "plt.plot(improved_metrics[\"train_losses\"], marker='o', label=\"Improved Train Loss\")\n",
    "plt.plot(improved_metrics[\"val_losses\"], marker='o', label=\"Improved Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs. Validation Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(baseline_metrics[\"train_accuracies\"], marker='o', label=\"Baseline Train Acc\")\n",
    "plt.plot(baseline_metrics[\"val_accuracies\"], marker='o', label=\"Baseline Val Acc\")\n",
    "plt.plot(improved_metrics[\"train_accuracies\"], marker='o', label=\"Improved Train Acc\")\n",
    "plt.plot(improved_metrics[\"val_accuracies\"], marker='o', label=\"Improved Val Acc\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training vs. Validation Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview:**\n",
    "\n",
    "The IMDb Large Movie Review Dataset has 25,000 movie reviews for training and 25,000 for testing. Theya are labeled as either positive (1) or negative (0). This dataset offers a balanced collection of reviews to capture a broad range of opinions and language styles. The dataset is provided by Stanford."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Architectures:**\n",
    "\n",
    "1. Baseline Architecture:\n",
    "    - The input words are first mapped into dense vector representations using an embedding layer. In this model, the embedding dimension is set to 100, which was chosen as a balance between capturing sufficient semantic information and maintaining computational efficiency.\n",
    "    - Here, three LSTM layers are used and they are responsible for capturing the sequencial dependencies in the text. Then hidden dimension of 128 is used for each LSTM layer this allow the model to learn complex representations of the input sequence. Also, dropout with a probability of 0.5 is applied between LSTM layers to avoid overfitting.\n",
    "    - The output from the final layer is connected to fully connected layer, it will map the hidden representation to two output logits corresponding to the positive and negative sentiment classes. I didn't used activation function as cross-entropy requires raw logits.\n",
    "\n",
    "2. Improved advanced architecture (GRU with Attention and Pre-trained GloVe Embeddings):\n",
    "    - Here, instead of learning embeddings from scratch, this model initializes its embedding layer with pre-trained GloVe vectors which is derived from a large corpus. As these embeddings are fixed, it allows the model to use rich, contextual semantic information learned from external data.\n",
    "    - Here, The recurrent component is replaced by a bidirectional Gated Recurrent Unit network, which has four GRU layers with a hidden dimension of 128. This bidirectional configuration enable the model to capture contextual information from both forward and backward passes through the input sequence. So, it will double the hidden state representation.\n",
    "    - An attention mechanism is applied on top of the GRU outputs, they helps to enhance the modelâ€™s focus on the most informative parts of the sequence. Also, a dedicated attention layer computes scalar attention scores for each time step, which are normalized via softmax to produce attention weights. These weights are used to compute a weighted sum of the GRU outputs and so it allows the model to dynamically prioritize relevant words or phrases in the review.\n",
    "    - Finally, the context vector generated by the attention mechanism is passed through a fully connected layer that outputs logits for the two sentiment classes. Here, the use of a bidirectional GRU and attention mechanism results in an input dimension for the FC layer that is twice the hidden dimension of a single GRU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization:**\n",
    "\n",
    "1. Baseline LSTM\n",
    "- The baseline model has accuracy around 50% for both training and validation, which means model is predicting randomly and the weights are not updating correctly.\n",
    "- Also, the validation loss for baseline model is decreased a bit. So, the modelâ€™s learned features do not generalize to unseen data.\n",
    "\n",
    "2. Improved LSTM\n",
    "- Improved modelâ€™s validation accuracy is around 90% by the last epoch, which is high compared to baseline model, which was not performing well. This shows the benefits of using pre-trained embeddings, a bidirectional GRU, and an attention mechanism.\n",
    "- Here, the improved modelâ€™s training and validation loss curves converge smoothly and they have a much smaller gap between training and validation metrics, which indicates that the model is generalized well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Strengths and Limitations:**\n",
    "\n",
    "1. Handling long sequences\n",
    "\n",
    "- LSTMs are designed to avoid the vanishing/exploding gradient problem found in vanilla RNNs. So, it allows them to better capture long-range dependencies within text.\n",
    "- But, LSTMs can struggle with extremely long sequences and sometimes they forget the earlier parts of the input if itâ€™s very lengthy or complex. In such cases transformers handle it more effectively.\n",
    "\n",
    "2. Computational cost\n",
    "\n",
    "- Compared to basic RNNs, LSTMs can learn better temporal dependencies with fewer issues related to gradient flow.\n",
    "- But the issue is that LSTM requires sequential training. So, it makes them less parallelizable compared to Transformer-based models. So, as sequence length and model size grow, the training time can become larger, and large hidden dimensions or many stacked layers leads to more computational and memory demands.\n",
    "\n",
    "3. Interpretability\n",
    "\n",
    "- LSTM gates offer some insight into how information flows and is retained or forgotten over time.\n",
    "- The limitation is that thay are still black-box neural networks compared to simpler models like logistic regression, where we can directly interpret feature weights. Also, without attention or some tools, it can be difficult to understand that which tokens or phrases are influencing the LSTMâ€™s predictions most.\n",
    "\n",
    "4. Sensitivity to hyperparameters\n",
    "\n",
    "- Here, LSTMs provide several hyperparameters to tune for improved performance. So, dropout and regularization techniques can be used to handle overfitting and improving generalization.\n",
    "- But that is also a limitation as the performance of LSTMs can be highly sensitive to these hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References:**\n",
    "\n",
    "https://pytorch.org/docs/stable/torch.html <br>\n",
    "https://pytorch.org/text/stable/index.html <br>\n",
    "https://amueller.github.io/word_cloud/ <br>\n",
    "https://www.nltk.org <br>\n",
    "https://scikit-learn.org/stable/user_guide.html <br>\n",
    "https://seaborn.pydata.org/tutorial.html <br>\n",
    "https://matplotlib.org/stable/users/index.html <br>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
