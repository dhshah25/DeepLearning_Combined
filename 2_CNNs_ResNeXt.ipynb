{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uxTtm5B_JgMq"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FgkYGl2wJeuY",
    "outputId": "bf12a18b-aa1d-4854-ca0d-eb57516f1149"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PqOpWXYqJiEe",
    "outputId": "673de0e9-11cc-470d-c698-d291868254c6"
   },
   "outputs": [],
   "source": [
    "!unzip \"/content/drive/MyDrive/cnn_dataset.zip\" -d \"/content/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KmqX_rNyghN6"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "lr = 0.001\n",
    "epochs = 20\n",
    "num_classes = 3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d07pZ2U4giG7"
   },
   "outputs": [],
   "source": [
    "data_dir = '/content/cnn_dataset'\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                         std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "full_dataset = datasets.ImageFolder(root=data_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ENOkGYAygrC3"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_indices, test_indices = train_test_split(\n",
    "    range(len(full_dataset)),\n",
    "    test_size=0.15,\n",
    "    random_state=42,\n",
    "    stratify=[sample[1] for sample in full_dataset.samples]\n",
    ")\n",
    "train_indices, val_indices = train_test_split(\n",
    "    train_indices,\n",
    "    test_size=0.1765,\n",
    "    random_state=42,\n",
    "    stratify=[full_dataset.samples[i][1] for i in train_indices]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NmaTeXYqgsTP"
   },
   "outputs": [],
   "source": [
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "val_dataset   = Subset(full_dataset, val_indices)\n",
    "test_dataset  = Subset(full_dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sINSNvSmg6Fv"
   },
   "outputs": [],
   "source": [
    "class ResNeXtBottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, cardinality=32, base_width=4, downsample=None):\n",
    "        super(ResNeXtBottleneck, self).__init__()\n",
    "        width = int(math.floor(out_channels * (base_width / 64.0))) * cardinality\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, width, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(width)\n",
    "        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=stride, padding=1,\n",
    "                               groups=cardinality, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(width)\n",
    "        self.conv3 = nn.Conv2d(width, out_channels * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNeXt(nn.Module):\n",
    "    def __init__(self, block, layers, cardinality=32, base_width=4, num_classes=num_classes):\n",
    "        super(ResNeXt, self).__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(64)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.Identity()\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64,  layers[0], stride=1, cardinality=cardinality, base_width=base_width)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, cardinality=cardinality, base_width=base_width)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, cardinality=cardinality, base_width=base_width)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, cardinality=cardinality, base_width=base_width)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride, cardinality, base_width):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * block.expansion)\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, cardinality, base_width, downsample))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, out_channels, stride=1, cardinality=cardinality, base_width=base_width))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6yA3e9Dfg-zm"
   },
   "outputs": [],
   "source": [
    "model_resnext = ResNeXt(ResNeXtBottleneck, layers=[2, 2, 2, 2], cardinality=32, base_width=4, num_classes=num_classes)\n",
    "model_resnext = model_resnext.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_resnext.parameters(), lr=lr, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v7OZyQNoJYT_",
    "outputId": "8205cd3f-2808-4196-c21c-02c69610b431"
   },
   "outputs": [],
   "source": [
    "train_loss_list, val_loss_list = [], []\n",
    "train_acc_list, val_acc_list = [], []\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_resnext.train()\n",
    "    running_train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_resnext(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += predicted.eq(labels).sum().item()\n",
    "\n",
    "    avg_train_loss = running_train_loss / len(train_loader)\n",
    "    train_acc = 100.0 * correct_train / total_train\n",
    "\n",
    "    model_resnext.eval()\n",
    "    running_val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model_resnext(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += predicted.eq(labels).sum().item()\n",
    "\n",
    "    avg_val_loss = running_val_loss / len(val_loader)\n",
    "    val_acc = 100.0 * correct_val / total_val\n",
    "\n",
    "    train_loss_list.append(avg_train_loss)\n",
    "    val_loss_list.append(avg_val_loss)\n",
    "    train_acc_list.append(train_acc)\n",
    "    val_acc_list.append(val_acc)\n",
    "\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}: \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.2f}% || \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model_resnext.state_dict(), 'resnext_best.pth')\n",
    "\n",
    "print(f\"Training Complete. Best Validation Accuracy: {best_val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HSrO9vYLhH8b",
    "outputId": "4352135c-0e87-4ac9-8148-94e0ef0d7583"
   },
   "outputs": [],
   "source": [
    "model_resnext.load_state_dict(torch.load('resnext_best.pth', map_location=device, weights_only=True))\n",
    "model_resnext.eval()\n",
    "\n",
    "test_loss = 0.0\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model_resnext(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_test += labels.size(0)\n",
    "        correct_test += predicted.eq(labels).sum().item()\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "avg_test_loss = test_loss / total_test\n",
    "test_acc = 100.0 * correct_test / total_test\n",
    "\n",
    "print(f\"Test Loss: {avg_test_loss:.4f} | Test Accuracy: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model    | Test Accuracy | Test loss |\n",
    "|----------|----------|----------|\n",
    "| VGG     | 93.83  | 0.1848 |\n",
    "| ResNet  | 93.73  | 0.1685  |\n",
    "| ResNeXt  | 93.78  | 0.2067  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "N6C4xU2fJ1yL",
    "outputId": "b84cc095-34fb-4221-901f-8aad7aea450f"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_loss_list, label='Train Loss')\n",
    "plt.plot(val_loss_list, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('ResNeXt Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "JtOlI0EQhNTr",
    "outputId": "e70d6186-fe76-48f3-bb85-e3dacc54adb2"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_acc_list, label='Train Accuracy')\n",
    "plt.plot(val_acc_list, label='Val Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('ResNeXt Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**\n",
    "\n",
    "- Here, the accuracy of ResNeXt is slighly better than ResNet. Although, the accuracy of VGG IS high. In part 1 we choose ResNet as our best model due to it's efficiency and slighly less loss compared to minor difference in accuracy of VGG. The design of ResNeXt with grouped convolutions and higher cardinality can capture more diverse feature representation and leads to better accuracy.\n",
    "\n",
    "- Here, the loss of ResNeXt is definitely higher than the other models but if we tune model better than it is possible to get the higher accuracy with even less loss.\n",
    "\n",
    "- The use of grouped convolutions in ResNeXt allow multiple parallel feature transformations. So, it is more powerful than the single path convolutions of ResNet. Here, both ResNet and ResNeXt use residual connections and it helps with gradient flow and convergence. But for this dataset and our configuration there is not much change in accuracy. Here, in ResNeXt there is concept of cardinality, which is number of parallel paths within convolutional layers. So, If we split 3 * 3 convolution into multiple groups, then the model will learn different features easily. This should lead to more accuracy but in our case there is very slight differece, which can be tuned to get higher accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenges**\n",
    "\n",
    "- Sensitivity to hyperparameters. Trying different learning rates, weight decay and the number of groups or cardinality required.\n",
    "\n",
    "- The architecture is more complex so it took longer than the previous model of ResNet. For this it took 75 minutes with T4 GPU.\n",
    "\n",
    "- ResNeXt also requires careful computation of the intermediate channel widths using base width and cardinality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**\n",
    "\n",
    "- ResNeXt has slighly higher accuracy than the ResNet but at the cost of high loss. So, our previous model of ResNet is better choice with less loss compared to this. This model can be improved further but we need to tune it even more and run more number of epochs for better comparison.\n",
    "\n",
    "- The results means that even if the innovative grouped convolutions and increased cardinality in ResNeXt can be helpful, these benefits may only become significant in a case where the dataset complexity or training might challenges the modelâ€™s representational capacity. In our experiment, the improvements in feature diversity did not led to significant reduction in loss so we cannot say that it completely outperform ResNet, but if we tune it further it will definitely show the better results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References:**\n",
    "\n",
    "https://arxiv.org/abs/1611.05431 <br>\n",
    "https://matplotlib.org/stable/plot_types/index.html <br>\n",
    "https://pytorch.org/docs/stable/index.html <br>\n",
    "https://scikit-learn.org/stable/ <br>\n",
    "https://pandas.pydata.org/docs/user_guide/index.html#user-guide"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
